\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[brazil]{babel}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{amsmath}
\usepackage{amssymb}

\geometry{a4paper, left=3cm, right=2cm, top=3cm, bottom=2cm}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
        backgroundcolor=\color{backcolour},
        commentstyle=\color{codegreen},
        keywordstyle=\color{magenta},
        numberstyle=\tiny\color{codegray},
        stringstyle=\color{codepurple},
        basicstyle=\ttfamily\footnotesize,
        breakatwhitespace=false,
        breaklines=true,
        captionpos=b,
        keepspaces=true,
        numbers=left,
        numbersep=5pt,
        showspaces=false,
        showstringspaces=false,
        showtabs=false,
        tabsize=2
}

\lstset{style=mystyle}

	\title{Relat\'{o}rio de Projeto: Compilador SL}
\author{
        Cecilia Peret, Guilherme Silva \\
        	{BCC328 - Constru\c{c}\~{a}o de Compiladores I} \\
        DECOM/UFOP
}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
Este relat\'{o}rio descreve a implementa\c{c}\~{a}o do analisador l\'{e}xico e sint\'{a}tico do compilador para a linguagem educativa SL, desenvolvido como trabalho pr\'{a}tico da disciplina. O projeto inclui um lexer baseado em Megaparsec, um parser token-driven implementado com Megaparsec sobre uma sequ\^{e}ncia de tokens (token-stream Parsec), uma AST que agora inclui defini\c{c}\~{o}es de \texttt{struct} e fun\c{c}\~{o}es, e uma interface de linha de comando para testar o analisador.
\end{abstract}

	

\section{Introdu\c{c}\~{a}o}

A linguagem SL \'{e} uma linguagem pequena usada para exerc\'{i}cios de compiladores. O objetivo deste trabalho foi implementar as fases iniciais do front-end de um compilador: an\'{a}lise l\'{e}xica e an\'{a}lise sint\'{a}tica, produzindo uma \'{A}rvore de Sintaxe Abstrata (AST) que pode ser usada em fases posteriores (an\'{a}lise sem\^{a}ntica, gera\c{c}\~{a}o de c\'{o}digo).

O projeto foi desenvolvido em Haskell usando a biblioteca Megaparsec para o lexer e uma implementa\c{c}\~{a}o manual de parser que consome tokens produzidos pelo lexer.

\section{Metodologia}

O desenvolvimento seguiu um ciclo iterativo: primeiro implementar o lexer, gerar tokens sobre arquivos de teste; em seguida implementar o parser por cima da lista de tokens. Para depura\c{c}\~{a}o, o projeto inclui uma interface CLI que permite imprimir tokens (modo \texttt{--lexer}) e tentar construir a AST (modo \texttt{--parser}).

Adicionalmente, foram implementados n\'{o}s m\'{o}dulos auxiliares para visualiza\c{c}\~{a}o no terminal:
\begin{itemize}
    \item \texttt{Pretty.hs}: Respons\'{a}vel pela formata\c{c}\~{a}o do c\'{o}digo (pretty printing), reconstruindo a s\'{i}ntaxe a partir da AST para exibi\c{c}\~{a}o leg\'{i}vel.
    \item \texttt{ASTtoTree.hs}: Utiliza a biblioteca \texttt{Data.Tree} para gerar uma representa\c{c}\~{a}o hier\'{a}rquica (floresta) da AST, facilitando a verifica\c{c}\~{a}o da estrutura sint\'{a}tica analisada via terminal.
\end{itemize}

As decis\~{o}es principais foram:
\begin{itemize}
    \item \textbf{Escolha do Megaparsec:} Optou-se pelo uso do Megaparsec em detrimento de ferramentas tradicionais como Alex e Happy. O Megaparsec permite escrever analisadores l\'{e}xicos e sint\'{a}ticos de forma unificada e mais idiom\'{a}tica em Haskell (combinadores mon\'{a}dicos), oferecendo melhor integra\c{c}\~{a}o com a linguagem e mensagens de erro superiores, sem a necessidade de geradores de c\'{o}digo externos.
    \item usar Megaparsec tanto no lexer quanto no parser: o lexer usa Megaparsec para tokenizar e preservar \texttt{SourcePos} em cada token, e o parser agora opera sobre um token-stream (\texttt{Parsec} sobre \texttt{[SLToken]}) usando primitivas de Megaparsec para corresponder tokens;
    \item manter a AST simples e evoluir conforme os testes --- a AST foi expandida para incluir \texttt{Definition} e \texttt{Struct}, al\'{e}m de suporte a literais de struct, arrays, \texttt{new}, chamadas e la\c{c}os.
\end{itemize}

\section{Linguagem: estrutura sint\'{a}tica de SL}

O analisador implementado cobre um subconjunto expressivo da linguagem SL, com as seguintes constru\c{c}\~{o}es (exemplos):
\begin{itemize}
    \item literais: inteiros, floats, strings, booleanos;
    \item identificadores e chamadas de fun\c{c}\~{a}o: \texttt{f(x, y)};
    \item arrays e literais de arrays: \texttt{a[i]}, \texttt{[1,2,3]};
    \item express\~{a}o \texttt{new T[e]} para cria\c{c}\~{a}o de arrays;
    \item declara\c{c}\~{o}es \texttt{let}, instru\c{c}\~{o}es \texttt{return}, \texttt{if/else}, \texttt{while}, \texttt{for};
    \item defini\c{c}\~{a}o de fun\c{c}\~{a}o: \texttt{func name(params) : retType \{ ... \}};
    \item suporte b\'{a}sico a tipos primitivos (\texttt{int}, \texttt{float}, \texttt{string}, \texttt{bool}) e tipos de usu\'{a}rio (identificadores como nomes de tipo) com sufixos de array (\texttt{T[]}, \texttt{T[n]}).
\end{itemize}

\section{Gram\'{a}tica Formal}

A gram\'{a}tica implementada, descrita em nota\c{c}\~{a}o de Gramática Livre de Contexto (GLC), \'{e} apresentada abaixo.

\begin{lstlisting}[basicstyle=\ttfamily\scriptsize]
Program -> TopLevels

TopLevels -> TopLevel TopLevels
           | lambda

TopLevel -> StructDef
          | FuncDef

StructDef -> struct id { StructFields }

StructFields -> StructField StructFields
              | lambda

StructField -> id : Type ;

FuncDef -> GenericsOpt func id ( ParamsOpt ) TypeRetOpt { Stmts }

GenericsOpt -> forall id GenIds .
             | lambda

GenIds -> id GenIds
        | lambda

ParamsOpt -> Params
           | lambda

Params -> Param ParamsTail

ParamsTail -> , Param ParamsTail
            | lambda

Param -> id TypeOpt

TypeRetOpt -> : Type
            | lambda

TypeOpt -> : Type
         | lambda

Type -> BaseType ArraySuffixes

ArraySuffixes -> ArraySuffix ArraySuffixes
               | lambda

ArraySuffix -> []
             | [ int_lit ]

BaseType -> FuncType
          | PrimitiveType
          | id

PrimitiveType -> int | float | string | bool | void

FuncType -> ( TypeListOpt ) ArrowOpt

TypeListOpt -> Type TypeListTail
             | lambda

TypeListTail -> , Type TypeListTail
              | lambda

ArrowOpt -> -> Type
          | lambda

Stmts -> Stmt Stmts
       | lambda

Stmt -> return Expr ;
      | let id TypeOpt InitOpt ;
      | if ( Expr ) { Stmts } ElseOpt
      | while ( Expr ) { Stmts }
      | for ( ForInitOpt ; Expr ; ExprOpt ) { Stmts }
      | Expr ;

InitOpt -> = Expr
         | lambda

ElseOpt -> else { Stmts }
         | lambda

ForInitOpt -> ForInit
            | lambda

ForInit -> let id TypeOpt InitOpt
         | Expr

ExprOpt -> Expr
         | lambda

Expr -> PrefixExpr ExprTail

ExprTail -> BinOp PrefixExpr ExprTail
          | lambda

PrefixExpr -> ++ PrefixExpr
            | -- PrefixExpr
            | ! PrefixExpr
            | Term

Term -> int_lit
      | float_lit
      | string_lit
      | new BaseType [ Expr ]
      | [ ExprListOpt ]
      | ( Expr )
      | id
      | Term Postfix

ExprListOpt -> Expr ExprListTail
             | lambda

ExprListTail -> , Expr ExprListTail
              | lambda

Postfix -> [ Expr ]
         | . id
         | ( ExprListOpt )
         | ++
         | --

BinOp -> + | - | * | / | < | > | <= | >= | == | != | && | || | =
\end{lstlisting}

\section{Sistema de tokens e an\'{a}lise l\'{e}xica}

O lexer est\'{a} em \texttt{workspace/src/Lexer.hs}. Ele usa Megaparsec e produz tokens definidos em \texttt{workspace/src/SLToken.hs}. Cada token carrega a posi\c{c}\~{a}o de origem (\texttt{SourcePos}), o que facilita mensagens de erro informativas.

Principais pontos do lexer:
\begin{itemize}
    \item reconhece palavras reservadas: \texttt{func}, \texttt{let}, \texttt{return}, \texttt{if}, \texttt{else}, \texttt{while}, \texttt{for}, \texttt{struct}, \texttt{new}, \texttt{forall}, \texttt{void} e tipos primitivos;
    \item reconhece operadores compostos (por exemplo, \texttt{++}, \texttt{->}, \texttt{==}, \texttt{!=}, \texttt{\&\&}, \texttt{||});
    \item produz tokens para pontua\c{c}\~{a}o: par\^{e}nteses, colchetes, chaves, dois-pontos, ponto, v\'{i}rgula e ponto-e-v\'{i}rgula;
    \item preserva coment\'{a}rios (s\~{a}o ignorados) e posicionamento no arquivo para cada token.
\end{itemize}

Arquivo relevante: \texttt{workspace/src/SLToken.hs} cont\'{e}m a enumera\c{c}\~{a}o \texttt{SLToken} com todos os construtores usados pelo parser.

Detalhes da implementa\c{c}\~{a}o do lexer
\begin{itemize}
    \item A fun\c{c}\~{a}o principal \'{e} \texttt{lexTokens :: String -> String -> Either (ParseErrorBundle String Void) [SLToken]} definida em \texttt{workspace/src/Lexer.hs}. Ela recebe o conte\'{u}do do arquivo e o nome do arquivo e retorna a lista de tokens ou um \texttt{ParseErrorBundle} do Megaparsec.
    \item O scanner de espa\c{c}os e coment\'{a}rios usa o combinador \texttt{L.space} com \texttt{space1}, \texttt{L.skipLineComment "//"} e \texttt{L.skipBlockComment "/*" "*/"} para ignorar espa\c{c}os e coment\'{a}rios antes de cada token (fun\c{c}\~{a}o \texttt{sc}).
    \item A ordem de escolha dos tokens em \texttt{pToken} \'{e} importante: primeiro palavras-chave, depois booleanos, n\'{u}meros (float antes de int), strings, s\'{i}mbolos, operadores e finalmente identificadores --- isso evita conflitos (por exemplo, a palavra-chave "func" n\~{a}o \'{e} reconhecida como identificador).
    \item Para cada token existe um parser dedicado: \texttt{pKeyword}, \texttt{pBool}, \texttt{pNumber} (com \texttt{pFloat} e \texttt{pInt}), \texttt{pString}, \texttt{pSymbol}, \texttt{pOperator} e \texttt{pIdent}. Cada parser captura a posi\c{c}\~{a}o atual com \texttt{getSourcePos} e constr\'{o}i o \texttt{SLToken} correspondente (por exemplo \texttt{TkIntLit n pos}).
    \item O parser de operadores reconhece sequ\^{e}ncias compostas (por exemplo \texttt{"->"}, \texttt{"\&\&"}, \texttt{"||"}, \texttt{"<="}, \texttt{"=="}, \texttt{"++"}, \texttt{"--"}) antes de operadores simples, para garantir que o token mais longo seja escolhido.
\end{itemize}

\section{An\'{a}lise sint\'{a}tica (parser)}

O parser principal est\'{a} em \texttt{workspace/src/Parser.hs}. Em vez de construir um parser combinat\'{o}rio sobre o texto, optou-se por um parser "token-driven": o lexer produz \texttt{[SLToken]} e o parser consome essa lista com uma m\'{a}quina simples.

Arquitetura do parser:
\begin{itemize}
    \item tipo de parser: o parser agora \'{e} um \texttt{Parsec} que consome um stream de \texttt{[SLToken]} (ou seja, \texttt{type Parser = Parsec Void [SLToken]}). Em vez de manipular o estado de tokens manualmente, usamos as primitivas de Megaparsec para token streams com fun\c{c}\~{o}es auxiliares;
    \item utilit\'{a}rios: \texttt{matchTok} (extrai valores de tokens via um \texttt{SLToken -> Maybe a}) e \texttt{satisfyTok} (testa predicados \texttt{SLToken -> Bool}) encapsulam a chamada a \texttt{token} do Megaparsec e simplificam o reconhecimento de palavras-chave, s\'{i}mbolos e literais;
    \item itens de topo: o parser aceita tanto defini\c{c}\~{o}es de \texttt{struct} quanto de \texttt{func} (representadas no c\'{o}digo como \texttt{Definition} com constructors \texttt{DefStruct} e \texttt{DefFunc}); structs s\~{a}o consumidos e armazenados na AST (n\~{a}o mais descartados);
    \item express\~{o}es: implementado usando \texttt{makeExprParser} (tabela de operadores) para preced\^{e}ncia, com \texttt{pPostfix} para indexa\c{c}\~{a}o, acesso a campo, chamadas e literais de struct no formato \texttt{Ident\{...\}}; postfix ++/-- tamb\'{e}m s\~{a}o suportados;
    \item instru\c{c}\~{o}es: \texttt{let} (com inicializador e tipo opcionais), \texttt{return}, \texttt{if/else}, \texttt{while} e \texttt{for} (com inicializador, condi\c{c}\~{a}o e incremento analisados);
    \item tipos: \texttt{pType} aceita tipos primitivos, identificadores de tipo e sufixos de array como \texttt{[]}/\texttt{[n]}, al\'{e}m de uma forma simples de tipo fun\c{c}\~{a}o \texttt{(a) -> b} representada como string.
\end{itemize}

O parser produz uma AST definida em \texttt{Parser.hs} com os construtores principais:
\begin{itemize}
    \item \texttt{Definition}: \texttt{DefFunc Func} ou \texttt{DefStruct Struct} --- o topo do arquivo pode conter ambas defini\c{c}\~{o}es;
    \item \texttt{Struct}: nome e lista de campos (pares nome/tipo);
    \item \texttt{Expr}: \texttt{EInt}, \texttt{EFloat}, \texttt{EString}, \texttt{EVar}, \texttt{ECall} (usado tamb\'{e}m para literais de struct no formato atual), \texttt{EArray}, \texttt{ENew}, \texttt{EBin}, \texttt{EPost};
    \item \texttt{Stmt}: \texttt{SReturn}, \texttt{SLet}, \texttt{SIf}, \texttt{SWhile}, \texttt{SFor}, \texttt{SExpr}.
\end{itemize}

\section{\'{A}rvore de sintaxe abstrata}

A AST \'{e} mantida simples e orientada \`{a}s necessidades imediatas do parser. Ela \'{e} suficiente para representar programas de teste e permite futuras fases de checagem de tipos e gera\c{c}\~{a}o de c\'{o}digo.

Exemplo de n\'{o}: uma atribui\c{c}\~{a}o via \'{i}ndice, como \texttt{result[i] = f(v[i]);}, \'{e} representada usando n\'{o}s de indexa\c{c}\~{a}o (no parser implementado como um \texttt{EBin "[]"}) e atribui\c{c}\~{a}o como um \texttt{EBin "="} com o lado esquerdo e direito apropriados.

\section{An\'{a}lise sem\^{a}ntica e gera\c{c}\~{a}o de c\'{o}digo}

Estas fases n\~{a}o foram implementadas integralmente no escopo atual. O projeto fornece a base (tokens + AST) necess\'{a}ria para implementar:
\begin{itemize}
    \item checagem est\'{a}tica de tipos e infer\^{e}ncia;
    \item resolu\c{c}\~{a}o de nomes e verifica\c{c}\~{a}o de escopo;
    \item gera\c{c}\~{a}o de c\'{o}digo intermedi\'{a}rio (por exemplo, uma IR simples) ou tradu\c{c}\~{a}o para C/WebAssembly.
\end{itemize}

\section{Modo de uso}

O projeto inclui um execut\'{a}vel chamado \texttt{sl} que pode ser executado via Cabal no diret\'{o}rio \texttt{workspace}. Exemplos de uso:

\begin{lstlisting}
cd workspace
make build        # executa 'cabal build' via Makefile
make lexer        # roda o lexer sobre os arquivos em TESTS (ou passe arquivos como argumentos)
make parser       # roda o parser sobre os arquivos em TESTS
make pretty       # executa a saida 'pretty' (formatacao) sobre os arquivos em TESTS
make test         # executa lexer, parser e pretty em sequencia

# Exemplos de uso com arquivos especificos:
# make lexer TESTS=test/ex6.sl
# make parser TESTS=test/ex6.sl
\end{lstlisting}

O reposit\'{o}rio tamb\'{e}m inclui um \texttt{docker-compose} para facilitar execu\c{c}\~{a}o em um container conforme instru\c{c}\~{o}es no \texttt{README.md} do projeto.

\section{Testes realizados}

Foram utilizados arquivos de exemplo (por exemplo \texttt{test/ex2.sl}, \texttt{test/ex3.sl}, \texttt{test/ex6.sl}) para validar o lexer e o parser. Durante o desenvolvimento foram corrigidos problemas como:
\begin{itemize}
    \item tokens com posi\c{c}\~{a}o (SourcePos) que exigiram padr\~{o}es de correspond\^{e}ncia com campos extras;
    \item parsing de acesso a campos (ponto) e indexa\c{c}\~{a}o dentro de express\~{o}es de tamanho (por exemplo, \texttt{new b[v.size]});
    \item suporte a declara\c{c}\~{o}es de \texttt{struct} de topo e literais de struct no formato \texttt{Type\{v1, v2, ...\}} (por exemplo, \texttt{Person{"Alice", 25, 1.65}});
    \item aceita\c{c}\~{a}o de tipos de par\^{a}metro opcionais e inicializadores opcionais em \texttt{let};
    \item suporte a literais de array e \`{a} express\~{a}o \texttt{new T[e]}.
    \item Foram criados 6 arquivos de teste cobrindo diversas constru\c{c}\~{o}es da linguagem SL. Todos est\~{a}o localizados na pasta test
\end{itemize}

\section{An\'{a}lise Sem\^{a}ntica (Etapa 2)}

A segunda etapa do trabalho focou na implementa\c{c}\~{a}o da an\'{a}lise sem\^{a}ntica e verifica\c{c}\~{a}o de tipos. O m\'{o}dulo \texttt{TypeChecker.hs} foi criado para realizar as seguintes valida\c{c}\~{o}es:

\begin{itemize}
    \item \textbf{Verifica\c{c}\~{a}o de Tipos:} Valida\c{c}\~{a}o de tipos primitivos (\texttt{int, float, bool, string, void}) e tipos complexos (arrays, structs). O sistema de tipos \'{e} estrito, impedindo opera\c{c}\~{o}es entre tipos num\'{e}ricos diferentes (ex: \texttt{int + float}) para garantir seguran\c{c}a e clareza.
    \item \textbf{Verifica\c{c}\~{a}o de Escopo (Declara\c{c}\~{a}o \'{U}nica):} Implementa\c{c}\~{a}o de uma tabela de s\'{i}mbolos baseada em pilha (\texttt{Env}). Garante que um identificador n\~{a}o seja redeclarado no mesmo escopo, permitindo o sombreamento (\textit{shadowing}) de vari\'{a}veis em escopos internos.
    \item \textbf{An\'{a}lise de Fun\c{c}\~{o}es:} Valida\c{c}\~{a}o de chamadas de fun\c{c}\~{a}o (aridade e tipos de argumentos), al\'{e}m de suporte a fun\c{c}\~{o}es de ordem superior (HOF).
    \item \textbf{Acesso a Dados:} Verifica\c{c}\~{a}o de acesso a campos de \texttt{struct} e indexa\c{c}\~{a}o de arrays, garantindo que o alvo possua o campo ou suporte indexa\c{c}\~{a}o.
    \item \textbf{Infer\^{e}ncia Local e Gen\'{e}ricos:} O compilador infere tipos em declara\c{c}\~{o}es \texttt{let} e loops \texttt{for}, al\'{e}m de suportar unifica\c{c}\~{a}o b\'{a}sica para fun\c{c}\~{o}es gen\'{e}ricas (\texttt{forall}).
\end{itemize}

O verificador de tipos percorre a AST e reporta erros sem\^{a}nticos detalhados.

\subsection{Ambiente do verificador de tipos}

O verificador de tipos utiliza um ambiente (registro Haskell chamado \texttt{Env}) que centraliza o estado necessário durante a checagem. A definição usada no código \texttt{workspace/src/TypeChecker.hs} é a seguinte:

\begin{lstlisting}[language=Haskell]
data Env = Env
    { vars    :: Map String Type                 -- Todas as variáveis visíveis (incluindo escopos pais)
    , currentVars :: Map String Type             -- Variáveis declaradas APENAS no escopo atual
    , funcs   :: Map String ([String], [Type], Type)  -- (Genéricos, Argumentos, Retorno)
    , structs :: Map String (Map String Type)    
    , context :: [(Map String Type, Map String Type)] -- Pilha de (vars, currentVars)
    , retType :: Maybe Type                      
    , activeGens :: [String]                     -- Genéricos da função atual
    }
\end{lstlisting}

A escolha desta organização foi motivada por simplicidade e eficiência durante a travessia da AST. Abaixo explicamos cada campo e a razão de projeto:

\begin{itemize}
    \item \textbf{\texttt{vars :: Map String Type}} -- armazena todas as variáveis visíveis no ponto atual da checagem, incluindo as vindas de escopos pais. Usar \texttt{Map} permite buscas O(log n) e código claro ao consultar tipos de identificadores.
    \item \textbf{\texttt{currentVars :: Map String Type}} -- mantém apenas as variáveis declaradas no escopo corrente. Isso facilita detectar redeclarações no mesmo bloco (erro semântico) sem precisar comparar estruturas maiores de escopo.
    \item \textbf{\texttt{funcs :: Map String ([String], [Type], Type)}} -- tabela de assinaturas de funções: lista de genéricos (nomes), tipos dos argumentos e tipo de retorno. As assinaturas são coletadas antes de verificar corpos (fase \emph{collectSignatures}), o que permite chamadas recursivas e checagem de HOFs.
    \item \textbf{\texttt{structs :: Map String (Map String Type)}} -- mapeia nomes de \texttt{struct} para suas tabelas de campos (nome \textrightarrow tipo). Isso é usado para validar acessos a campos e construir tipos de literais/construtores de struct.
    \item \textbf{\texttt{context :: [(Map String Type, Map String Type)]}} -- pilha usada para implementar entrada/saída de escopos: ao entrar num bloco empilhamos o par (\texttt{vars},\texttt{currentVars}) e, ao sair, restauramos o par anterior. Essa estratégia simplifica rollback de alterações locais.
    \item \textbf{\texttt{retType :: Maybe Type}} -- guarda o tipo de retorno esperado da função corrente (se houver). Permite validar instruções \texttt{return} dentro do corpo da função.
    \item \textbf{\texttt{activeGens :: [String]}} -- lista de genéricos ativos no escopo da função corrente. É usada para interpretar strings de tipo que podem referir variáveis de tipo genérico (por exemplo, \texttt{forall a.}).
\end{itemize}


Uma parte central deste ambiente que merece uma explicação mais detalhada é o campo \texttt{context} (a pilha de pares \texttt{(vars,currentVars)}), pois ele governa o comportamento de escopos, sombreamento e restauração de estado durante a travessia da AST.

\paragraph{Por que armazenar \texttt{context} como um par?}
Armazenar o par \texttt{(vars,currentVars)} em cada nível da pilha tem três vantagens práticas no design deste verificador:
\begin{enumerate}
    \item \textbf{Restauração O(1)}: ao sair de um escopo basta desempilhar o par e repor \texttt{vars} e \texttt{currentVars} exatamente como estavam — não é preciso iterar sobre chaves ou reconstruir mapas. Empurrar e desempilhar são operações O(1) na lista que usamos como pilha.
    \item \textbf{Detecção fácil de redeclaração local}: como mantemos \texttt{currentVars} separado, checar "variável já declarada neste escopo" é apenas uma busca em \texttt{currentVars} (O(log n) na implementação com \texttt{Map}). Não precisamos fazer buscas complexas nem comparar com o mapa pai.
    \item \textbf{Semântica de shadowing explícita}: quando uma variável local sombreia um nome de escopo pai, atualizamos \texttt{vars} com o novo mapeamento e guardamos o mapa antigo no par. Ao restaurar, o nome sombreado retorna ao seu estado anterior automaticamente.
\end{enumerate}

\paragraph{Custo comparado a alternativas}
Uma alternativa óbvia seria não manter \texttt{vars} global e, em vez disso, procurar um identificador caminhando pela pilha de \texttt{currentVars} do topo até a raiz (modelo de pilha de níveis). Esse modelo tem a vantagem conceitual de ser puramente funcional, mas traz dois custos práticos:
\begin{itemize}
    \item cada lookup de variável pode precisar percorrer vários mapas (no pior caso, O(d \cdot log n) onde d é a profundidade de escopo), o que degrada performance em programas aninhados;
    \item ao sair de um escopo, não precisamos restaurar nada explicitamente — mas acabamos pagando a conta nas buscas.
\end{itemize}

Outra alternativa seria reconstruir \texttt{vars} ao sair do escopo removendo explicitamente todas as chaves presentes em \texttt{currentVars}; isso é funcionalmente correto mas implica custo proporcional ao número de variáveis locais (cada remoção é O(log n)).

Por isso o par \texttt{(vars,currentVars)} é um compromisso prático: lookups continuam rápidos (uma única busca em \texttt{vars}), declarações locais são fáceis de detectar (checar \texttt{currentVars}) e restauração do estado é direta (desempilhar o par). Para o escopo dos exercícios e exemplos da disciplina, essa escolha é simples e suficiente.

\paragraph{Exemplo passo-a-passo}
Segue um exemplo ilustrativo simplificado do conteúdo dos mapas durante a entrada/saída de um bloco.
\begin{lstlisting}[basicstyle=\ttfamily\small]
# Estado inicial
vars       = { x : int, y : bool }
currentVars= { }
context    = [ ]

# Ao entrar em um bloco (enterScope):
context    = [ ({x:int,y:bool}, {}) ]
currentVars= {}

# Declaramos `let x : float = 0.0` dentro do bloco (shadowing):
currentVars= { x : float }
vars       = { x : float, y : bool }

# Ao sair do bloco (exitScope):
({oldVars,oldCurrent} : rest) = head context
vars       = oldVars       -- { x : int, y : bool }
currentVars= oldCurrent    -- { }
context    = rest
\end{lstlisting}

Esse exemplo mostra como o shadowing é tratado sem operações complexas ao sair do escopo: a restauração é um simples desempilhamento.

Implementacionalmente, o verificador de tipos roda dentro da monad transformer \texttt{ExceptT String (State Env)} (apelidada \texttt{CheckM}). Essa escolha reúne duas necessidades importantes:

\begin{itemize}
    \item tratamento de erros semânticos via \texttt{ExceptT} (mensagens claras e abortamento da checagem ao encontrar inconsistências),
    \item manutenção de estado mutável do ambiente via \texttt{State Env} (entrada/saída de escopos, inserção de variáveis, atualização de tabelas de funções/structs) sem passar explicitamente o ambiente em todos os parâmetros.
\end{itemize}

Algumas decisões de projeto e trade-offs:
\begin{itemize}
    \item separar \texttt{currentVars} de \texttt{vars} facilita detectar redeclarações no mesmo nível e implementar shadowing de forma clara (variáveis novas são inseridas em \texttt{currentVars} e em \texttt{vars}).
    \item guardar as assinaturas de funções em \texttt{funcs} antes de verificar corpos permite suporte natural a recursão e checagem modular (checar chamadas usando apenas a assinatura).
    \item a representação de tipos (tipo \texttt{Type}) é tratada num módulo separado (\texttt{Types.hs}), mantendo o \texttt{Env} independente dos detalhes internos de tipos enquanto o acesso/compare é simples (\texttt{Eq} e construção de tipos compostos como \texttt{TArray} e \texttt{TFunc}).
    \item o modelo é intencionalmente simples e suficiente para o subconjunto da linguagem SL abordado; casos mais avançados (inferência completa, solução de restrições rica) exigiriam uma estrutura de ambiente e mecanismos de unificação mais sofisticados.
\end{itemize}

No código, funções auxiliares como \texttt{enterScope}, \texttt{exitScope}, \texttt{defineVar} e \texttt{lookupVar} encapsulam as operações sobre o \texttt{Env}, mantendo o restante do verificador concentrado nas regras de tipos e reduzindo repetição de manipulação de estado.

Abaixo estão trechos representativos dessas funções (retirados de \texttt{workspace/src/TypeChecker.hs}) e uma explicação do que fazem e por que são importantes:

\begin{lstlisting}[language=Haskell]
lookupVar :: String -> CheckM Type
lookupVar name = do
    st <- get
    case Map.lookup name (vars st) of
        Just t -> return t
        Nothing -> case Map.lookup name (funcs st) of
            Just (gens, args, ret) -> return (TFunc args ret)
            Nothing -> throwError $ "Variável não está no escopo: " ++ name

defineVar :: String -> Type -> CheckM ()
defineVar name t = do
    st <- get
    if Map.member name (currentVars st)
        then throwError $ "Variável já declarada neste escopo: " ++ name
        else put $ st { vars = Map.insert name t (vars st)
                      , currentVars = Map.insert name t (currentVars st) 
                      }

expectType :: Type -> Type -> CheckM ()
expectType expected actual = 
    if expected == actual 
    then return () 
    else throwError $ "Incompatibilidade de tipos: esperado " ++ show expected ++ ", obtido " ++ show actual
\end{lstlisting}

Explicação e motivação:
\begin{itemize}
    \item \textbf{\texttt{lookupVar}}: Pesquisa primeiro em \texttt{vars} (mapa que contém todas as variáveis visíveis). Se não encontrar um identificador, tenta \texttt{funcs} — isto permite tratar chamadas a funções nomeadas mesmo quando não há uma entrada específica em \texttt{vars} (as funções têm assinaturas guardadas em \texttt{funcs}). Se tudo falhar, lança um erro indicando que o identificador não está no escopo.
    \item \textbf{\texttt{defineVar}}: Antes de inserir uma nova variável, verifica \texttt{currentVars} para evitar redeclarações no mesmo escopo (erro semântico). Se a variável não existe no escopo atual, insere a nova entrada em \texttt{currentVars} (para detectar redeclarações futuras neste escopo) e em \texttt{vars} (para que buscas posteriores encontrem o identificador rapidamente). Essa duplicação é intencional e compatível com o uso do par \texttt{(vars,currentVars)} na pilha de \texttt{context}.
    \item \textbf{\texttt{expectType}}: Função utilitária que compara tipos esperados e obtidos; em caso de discrepância, emite uma mensagem de erro legível com os dois tipos (apoiando a depuração). Centralizar essa checagem evita repetição de código por toda a verificação de expressões e comandos.
\end{itemize}

Essas funções mantêm o verificador simples e modular: \texttt{lookupVar}/\texttt{defineVar} encapsulam a política de escopos e sombreamento; \texttt{expectType} encapsula a lógica de erro ao comparar tipos. Juntas, elas permitem que as regras de checagem (por exemplo, em \texttt{checkExpr} e \texttt{checkStmt}) continuem legíveis e diretas, delegando a infraestrutura de estado/erros ao \texttt{Env} e ao \texttt{CheckM}.


\section{Interpretador (Etapa 2)}

O m\'{o}dulo \texttt{Interpreter.hs} implementa a sem\^{a}ntica operacional da linguagem SL, permitindo a execu\c{c}\~{a}o direta da AST.

\begin{itemize}
    \item \textbf{Ambiente de Execu\c{c}\~{a}o:} Utiliza uma pilha de escopos (\texttt{[Map String Value]}) para gerenciar o estado das vari\'{a}veis, permitindo que altera\c{c}\~{o}es em loops e blocos persistam corretamente.
    \item \textbf{L-Values e Atribui\c{c}\~{a}o:} Suporte a atribui\c{c}\~{o}es complexas (campos de structs e \'{i}ndices de arrays).
    \item \textbf{Recurs\~{a}o:} Suporte total a chamadas recursivas através do isolamento de contextos de ativa\c{c}\~{a}o.
    \item \textbf{Mem\'{o}ria:} Gerenciamento dinâmico de arrays e structs durante a execu\c{c}\~{a}o.
\end{itemize}

\section{Formaliza\c{c}\~{a}o Matem\'{a}tica}

Nesta se\c{c}\~{a}o, apresentamos o projeto formal do sistema de tipos e da sem\^{a}ntica operacional da linguagem SL, fundamentando o comportamento do analisador sem\^{a}ntico e do interpretador desenvolvidos na Etapa 2.

\subsection{Sistema de Tipos (Regras de Infer\^{e}ncia)}
O sistema de tipos \'{e} formalizado atrav\'{e}s de julgamentos do tipo $\Gamma \vdash e : \tau$, indicando que no contexto $\Gamma$ (ambiente de tipos), a express\~{a}o $e$ possui o tipo $\tau$.

\textbf{Vari\'{a}veis e Literais:}
\[
\frac{\Gamma(x) = \tau}{\Gamma \vdash x : \tau} (Var) \quad \frac{n \in \mathbb{Z}}{\Gamma \vdash n : \texttt{int}} (Int) \quad \frac{f \in \mathbb{R}}{\Gamma \vdash f : \texttt{float}} (Float)
\]

\textbf{Opera\c{c}\~{o}es Bin\'{a}rias:}
\[
\frac{\Gamma \vdash e_1 : \tau \quad \Gamma \vdash e_2 : \tau \quad \tau \in \{\texttt{int}, \texttt{float}\}}{\Gamma \vdash e_1 \ (+, -, *, /) \ e_2 : \tau} (Arith)
\]
\[
\frac{\Gamma \vdash e_1 : \tau \quad \Gamma \vdash e_2 : \tau \quad \tau \in \{\texttt{int}, \texttt{float}\}}{\Gamma \vdash e_1 \ (<, >, \le, \ge) \ e_2 : \texttt{bool}} (Rel)
\]

\textbf{Atribui\c{c}\~{a}o e Gen\'{e}ricos:}
\[
\frac{\Gamma \vdash e_1 : \tau \quad \Gamma \vdash e_2 : \tau}{\Gamma \vdash e_1 = e_2 : \tau} (Assign) \quad \frac{\Gamma \vdash f : \forall \alpha.\tau_1 \to \tau_2 \quad \Gamma \vdash e : \tau'_1 \quad S = satisfy(\tau_1, \tau'_1)}{\Gamma \vdash f(e) : apply(S, \tau_2)} (Polym)
\]

\textbf{Comandos de Controle:}
\[
\frac{\Gamma \vdash e : \texttt{bool} \quad \Gamma \vdash \{s_1\} \quad \Gamma \vdash \{s_2\}}{\Gamma \vdash \texttt{if} \ (e) \ \{s_1\} \ \texttt{else} \ \{s_2\}} (If) \quad \frac{\Gamma \vdash e : \texttt{bool} \quad \Gamma \vdash \{s\}}{\Gamma \vdash \texttt{while} \ (e) \ \{s\}} (While)
\]
\[
\frac{\Gamma \vdash s_{init} \quad \Gamma' \vdash e : \texttt{bool} \quad \Gamma' \vdash s_{incr} \quad \Gamma' \vdash \{s_{body}\}}{\Gamma \vdash \texttt{for} \ (s_{init}; e; s_{incr}) \ \{s_{body}\}} (For)
\]
\textit{Onde $\Gamma'$ \'{e} o ambiente estendido por eventuais declara\c{c}\~{o}es l\'{o}gicas em $s_{init}$.}

\subsection{Sem\^{a}ntica Operacional Big-Step}
A sem\^{a}ntica din\^{a}mica descreve como o estado $\sigma$ (mapeamento de vari\'{a}veis para valores) evolui durante a execu\c{c}\~{a}o.

\textbf{Avalia\c{c}\~{a}o de Express\~{o}es $(e, \sigma) \Downarrow v$:}
\[
\frac{\sigma(x) = v}{(x, \sigma) \Downarrow v} (Var) \quad \frac{(e_1, \sigma) \Downarrow v_{1} \quad (e_2, \sigma) \Downarrow v_{2} \quad v = v_{1} \oplus v_{2}}{(e_1 \oplus e_2, \sigma) \Downarrow v} (BinOp)
\]

\textbf{Execu\c{c}\~{a}o de Comandos $(s, \sigma) \Downarrow \sigma'$:}
\[
\frac{(e, \sigma) \Downarrow \texttt{true} \quad (s_1, \sigma) \Downarrow \sigma'}{(\texttt{if} \ e \ s_1 \ \texttt{else} \ s_2, \sigma) \Downarrow \sigma'} \quad \frac{(e, \sigma) \Downarrow \texttt{false} \quad (s_2, \sigma) \Downarrow \sigma'}{(\texttt{if} \ e \ s_1 \ \texttt{else} \ s_2, \sigma) \Downarrow \sigma'}
\]

\textbf{La\c{c}os e Expans\~{a}o:}
\[
\frac{(e, \sigma) \Downarrow \texttt{true} \quad (s, \sigma) \Downarrow \sigma_{1} \quad (\texttt{while} \ e \ s, \sigma_1) \Downarrow \sigma_{2}}{(\texttt{while} \ e \ s, \sigma) \Downarrow \sigma_2} \quad \frac{(e, \sigma) \Downarrow \texttt{false}}{(\texttt{while} \ e \ s, \sigma) \Downarrow \sigma}
\]
A sem\^{a}ntica do comando \texttt{for} \'{e} definida atrav\'{e}s de sua tradu\c{c}\~{a}o para um bloco contendo inicializa\c{c}\~{a}o e um la\c{c}o \texttt{while}:
\[
(for \ (i; c; p) \ \{b\}, \sigma) \Downarrow \sigma' \iff (\{ i; while \ (c) \ \{b; p\} \}, \sigma) \Downarrow \sigma'
\]

\textbf{Efeitos Colaterais (Prefix/Postfix):}
\[
\frac{\sigma(x) = n \quad \sigma' = \sigma[x \mapsto n+1]}{(++x, \sigma) \Downarrow (\sigma', n+1)} \quad \frac{\sigma(x) = n \quad \sigma' = \sigma[x \mapsto n+1]}{(x++, \sigma) \Downarrow (\sigma', n)}
\]

\section{Limita\c{c}\~{o}es e trabalho futuro}

Limita\c{c}\~{o}es atuais:
\begin{itemize}
    \item gera\c{c}\~{a}o de c\'{o}digo em desenvolvimento (Etapa 3);
    \item representa\c{c}\~{a}o de tipos na AST \'{e} simplificada (strings) e deve ser substitu\'{i}da por um AST de tipos dedicado;
    \item mensagens de erro do parser atualmente s\~{a}o retornadas como \texttt{String} (via \texttt{show} do \texttt{ParseErrorBundle}) --- podem ser melhor formatadas para uso interativo;
    \item o parser \'{e} manual e poderia ser refatorado para reduzir duplica\c{c}\~{a}o (por exemplo, usar combinadores mais declarativos ou um parser de preced\^{e}ncia completo).
\end{itemize}

\section{Gera\c{c}\~{a}o de C\'{o}digo (Etapa 3)}

A terceira etapa implementou a gera\c{c}\~{a}o de c\'{o}digo para WebAssembly (WAT).
Novos m\'{o}dulos:
\begin{itemize}
    \item \texttt{WAT.hs}: Define a AST do WebAssembly (WModule, WFunc, WInstr) e o Pretty Printer respons\'{a}vel por gerar o c\'{o}digo S-Expression final.
    \item \texttt{CodeGenerator.hs}: Percorre a AST da linguagem SL e traduz para instru\c{c}\~{o}es WAT.
\end{itemize}

Funcionalidades implementadas:
\begin{itemize}
    \item \textbf{Mapeamento de Tipos:} \texttt{int/bool} $\to$ \texttt{i32}, \texttt{float} $\to$ \texttt{f64}.
    \item \textbf{Express\~{o}es B\'{a}sicas:} Aritm\'{e}tica, compara\c{c}\~{o}es e chamadas de fun\c{c}\~{a}o.
    \item \textbf{Controle de Fluxo:} Tradução de \texttt{if}, \texttt{while}, \texttt{for} para constru\c{c}\~{o}es estruturadas do WASM (\texttt{block}, \texttt{loop}, \texttt{br\_if}).
    \item \textbf{Fun\c{c}\~{o}es:} Suporte a fun\c{c}\~{o}es, vari\'{a}veis locais e recurs\~{a}o.
    \item \textbf{Aloca\c{c}\~{a}o de Mem\'{o}ria (Arrays):} Implementa\c{c}\~{a}o de um alocador linear simples (bump allocator) usando var\'{i}avel global \texttt{\$free\_ptr}. Suporte a \texttt{new T[n]}, literais de array e acesso por \'{i}ndice.
\end{itemize}

O compilador gera c\'{o}digo WAT v\'{a}lido que pode ser convertido para bin\'{a}rio \texttt{.wasm} utilizando ferramentas como \texttt{wat2wasm}.

\section{Conclus\~{a}o}

O trabalho entregou um front-end inicial funcional para a linguagem SL: um lexer robusto baseado em Megaparsec e um parser token-driven que j\'{a} entende um conjunto razo\'{a}vel de constru\c{c}\~{o}es de linguagem. O artefato fornece uma base s\'{o}lida para as pr\'{o}ximas fases, como checagem de tipos e gera\c{c}\~{a}o de c\'{o}digo.
Apesar das limita\c{c}\~{o}es, o projeto demonstra conceitos fundamentais de an\'{a}lise l\'{e}xica e sint\'{a}tica em compiladores, servindo como um ponto de partida para futuras extens\~{o}es.

\section{Refer\^{e}ncias}

\begin{itemize}
    \item Megaparsec: Monadic parser combinators. Dispon\'{i}vel em: \url{https://hackage.haskell.org/package/megaparsec}. Acesso em: 14 dez. 2025.
\end{itemize}

\end{document}
